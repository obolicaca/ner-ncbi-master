{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-valuation",
   "metadata": {},
   "source": [
    "<img src=\"https://media2.giphy.com/media/BpGWitbFZflfSUYuZ9/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "leading-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-strand",
   "metadata": {},
   "source": [
    "# In this notebook we shall: \n",
    "* Discuss the choice of the dataset \n",
    "* Download the dataset \n",
    "* Preprocess it into a nicer form for NER  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-railway",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-restoration",
   "metadata": {},
   "source": [
    "# Dataset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-slovakia",
   "metadata": {},
   "source": [
    "* Since the topic of interest revolves around the medical field, I thought it would be a good idea to choose a dataset which reflects this\n",
    "* There a several contenders in the area which satisfy this condition, but I've decided to go with <b>NCBI disease</b>, which is a corpus for NER, which revolves around various disease entities ([more info](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/)) \n",
    "* This corpus is also present in the current research revolving the biomedical field and NER, for example: [paper1](https://arxiv.org/pdf/2011.06315v1.pdf) and [paper2](https://arxiv.org/pdf/1901.08746v4.pdf)\n",
    "* The corpus is already split into train/val/test sets. While we won't care much for validation set, we will be able to benchmark our models performence against [SOTA](https://paperswithcode.com/sota/named-entity-recognition-ner-on-ncbi-disease) (tho I'm not 100% sure if they are using the test set for the f1 score)\n",
    "* The size of the dataset is also suitable given my hardware constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-perfume",
   "metadata": {},
   "source": [
    "# Downloading the dataset and additional info\n",
    "* I've put the dataset into my google drive so we will download it from there\n",
    "* You can download the original dataset from [here](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/)\n",
    "* However, abstracts are not split into sentences, and it's quite time consuming to so do (sentence splitters in nltk and spacy, as an example, do not split some of the abstracts correctly\n",
    "* Therefore, we will be using dataset that is already split into sentences (kind of). Dataset taken from [here](https://github.com/dmis-lab/biobert)\n",
    "* Another bonus is that this NCBI dataset does have duplicate articles (removed)[https://arxiv.org/pdf/1901.08746v4.pdf)\n",
    "\n",
    "* Lastly, the sentences are tagged with only 3 targets, which indicate no disease, start of disease and continuation of disease. This kind of makes sense, since if we identify the disease we can just look it up in some disease dictionary, instead of having multiple various disease tags, which would make the problem much more complex. Also, I'm pretty sure that's the setup that is used for benchmarking (due I didn't look it up closely, so I may be incorrect here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yellow-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.downloader import downloader \n",
    "downloader(\"../data/raw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
