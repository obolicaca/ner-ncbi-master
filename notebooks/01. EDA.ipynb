{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sweet-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, \"..\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-palace",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "* In this section we shall look at your data and try to infer useful information\n",
    "* Additionally we shall test how our data plays along with bert tokenizers, specifically with distil bert tokenizers (we shall discuss the choice for transfer model later, maybe :D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-silly",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "* For now, we have pairs of inputs and targets in form [token1, token2..], [tag1, tag2]\n",
    "* However, Bert and bert like models use [wordpiece](https://stackoverflow.com/questions/55382596/how-is-wordpiece-tokenization-helpful-to-effectively-deal-with-rare-words-proble/55416944#55416944) embeddings, we must somehow account for that\n",
    "* A common way to do it is to split each word into it's word tokens, and tag each token with the label of the original word\n",
    "* On a side note, we shall be using cased tokenizer, as it seems that [cased](https://arxiv.org/pdf/1901.08746.pdf)  variant provides better results. Intuitively, this makes some sense: suppose an abbreviation \"LIKE\" is used. If we lower case this bad boy, it will become harder to distinguish between \"like\" the abbreviation and like the word. Abusing Capital letter information makes the task easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-forty",
   "metadata": {},
   "source": [
    "# Chosing sequence length\n",
    "\n",
    "* As I recall, bert and distill bert both provide max input length of 512. We would like to not exceed this amount as we would have to use something like a sliding window approach which would add large computational overhead\n",
    "* We would also like to input only enough tokens to satisfy our input lengths, as padding whole [512 - tokens] inputs and passing them to transformer would incur additional computational overhead, not mentioning dealing with other issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "marine-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from collections import defaultdict\n",
    "from core.config import config \n",
    "from core.visual import vis_token_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggressive-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = joblib.load(\"../data/proc/train.bin\")\n",
    "tokenizer = config[\"tokenizer\"][\"TOKENIZER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "whole-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "tokenized_sentences = []\n",
    "for sent in x:\n",
    "    sent_len = 2 # [CLS] + [SEP] token \n",
    "    new_sent = []\n",
    "    for word in sent:\n",
    "        w_pieces = tokenizer.encode(word, add_special_tokens=False)\n",
    "        sent_len += len(w_pieces)  \n",
    "        new_sent.extend(w_pieces)\n",
    "        \n",
    "    lengths.append(sent_len)   \n",
    "    tokenized_sentences.append([101] + new_sent + [102])  \n",
    "    \n",
    "assert(len(lengths) == len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-identifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_token_counts(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-isaac",
   "metadata": {},
   "source": [
    " * Looks like most sentences are below 100 tokens. Let's be safe and set max length to a little bit more than our outlier (around 175) to 180 tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-ocean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(config[\"tokenizer\"][\"MAX_LEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-steel",
   "metadata": {},
   "source": [
    "# Checking how many UNK tokens we have\n",
    "\n",
    "* Out of curiousity, let's check how many unkown tokens we have (no vocab mapping and can't split into word pieces)\n",
    "* High amount of UNK tokens may let us want to rethink if we would like to select another tokenization/model approach\n",
    "* We will be ignoring all data from test set in order to remain as unbiased as we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emerging-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n_unk = []\n",
    "for sent in tokenized_sentences:\n",
    "    unk_cnt = 0\n",
    "    for token in sent:\n",
    "        if token == tokenizer.unk_token_id: unk_cnt += 1\n",
    "    n_unk.append(unk_cnt)  \n",
    "print(sum(n_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-victoria",
   "metadata": {},
   "source": [
    "* Hmm, sounds a bit too good to be true lol\n",
    "* Well, for the sake of time, let's just assume that this is corret, but I would look a little bit more in-depth into this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-blade",
   "metadata": {},
   "source": [
    "# Checking target token distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advance-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: O | COUNT: 168538 | RATIO: 0.9183\n",
      "LABEL: B | COUNT: 6704 | RATIO: 0.0365\n",
      "LABEL: I | COUNT: 8291 | RATIO: 0.0452\n"
     ]
    }
   ],
   "source": [
    "encoder = joblib.load(\"../data/label_encoder.bin\")\n",
    "cnts = defaultdict(lambda  : 0)\n",
    "\n",
    "for sent_targets in y:\n",
    "    for s_t in sent_targets:\n",
    "        cnts[s_t] += 1\n",
    "\n",
    "total = sum(cnts.values()) \n",
    "for k, v in cnts.items():\n",
    "    print(f\"LABEL: {encoder.inverse_transform([k])[0]} | COUNT: {v} | RATIO: {(v/ total):.4f}\" )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-university",
   "metadata": {},
   "source": [
    "* As expected, most tags are tagged with no entity tag\n",
    "* Since we will be using cross-entropy loss, this may cause some problems as loss may be biased towards majority class (I can't recall whether something in bert architecture or AdamW optimizer adjusts for that)\n",
    "* However, I did a little exploring at seems that everybody I looked at, including kaggle grandmasters just use standard torches nn.CrossEntropy loss, so I'll just follow their lead :D\n",
    "* We would try to adjust weights, since torches cross entropy can take in class weights to pay more/less attention to specific classes, but for now let's leave it as it is and see how we do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-louis",
   "metadata": {},
   "source": [
    "# Checking for dublicates\n",
    "\n",
    "* The dataset was taken from the authors of [this](https://arxiv.org/pdf/1901.08746v4.pdf) paper, and they claim that the dublicates have been removed.\n",
    "* Normally, this is a rather important step and should be performed in most scenarios: we can do a lot of stuff here from simple levenstein distance comparisons, cosine distances between tokens etc. to something more complex like measuring distances between embedded samples, while also adjusting for loss of information by introducing and additional static embedding which will not change while maintaining static embeddings, something similar to what one could see for CNN text classifiers. Well, something like that :D\n",
    "* we could also think of various techniques to undersample, oversample etc., but will have to figure out what these terms mean for this problem :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
