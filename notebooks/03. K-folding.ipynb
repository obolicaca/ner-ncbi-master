{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genuine-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-capital",
   "metadata": {},
   "source": [
    "# K-folding\n",
    "\n",
    "* Let's try to k-fold our data.\n",
    "* Testing our model performance on different train and valid sets increases the likelihood that our model\n",
    "* (and getting good results with low variance) will generalize better to unseen data \n",
    "* Since our targets are sequences, getting getting the \"comparable\" distribution will take a little bit of creativity, as normal stratified k folding won't work and we kind of have to establish what \"distribution\" we have in mind\n",
    "* ^ But let's just ignore that and do random Kfolding and pray to Lord Andrew that this will work out :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "from core.utils import split_into_k_folds \n",
    "from core.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_into_k_folds(\"../data/proc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-wyoming",
   "metadata": {},
   "source": [
    "# Checking label ratios for our folds \n",
    "\n",
    "* We can check many things for validating the \"goodnes-of-split\", but let's limit ourselves by calculating ratios\n",
    "* of our tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "flexible-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAIN VAL LENGTHS OF FOLD1: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD2: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD3: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD4: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD5: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD6: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD7: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD8: 6541 727\n",
      "TAIN VAL LENGTHS OF FOLD9: 6542 726\n",
      "TAIN VAL LENGTHS OF FOLD10: 6542 726\n"
     ]
    }
   ],
   "source": [
    "folds_dir = Path(\"../data/k-fold\"); assert folds_dir.exists()\n",
    " \n",
    "tag_dists = {} \n",
    "for i in range(1, 11):\n",
    "    fold_k_dir = folds_dir / f\"fold{i}\"; assert fold_k_dir.exists()\n",
    "    \n",
    "    train_k = joblib.load(fold_k_dir / \"train.bin\")\n",
    "    val_k = joblib.load(fold_k_dir / \"val.bin\")\n",
    "    print(f\"TAIN VAL LENGTHS OF FOLD{i}: {len(train_k[0])} {len(val_k[0])}\")\n",
    "    \n",
    "    train_k_tags = defaultdict(lambda : 0)\n",
    "    for tag_seq in train_k[1]:\n",
    "        for tag in tag_seq:\n",
    "            train_k_tags[tag] +=1\n",
    "     \n",
    "    val_k_tags = defaultdict(lambda : 0)\n",
    "    for tag_seq in val_k[1]:\n",
    "        for tag in tag_seq:\n",
    "            val_k_tags[tag] +=1\n",
    "    \n",
    "    tag_dists[i] = {\"train\": train_k_tags, \"val\": val_k_tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clinical-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD1 | (6006, 7482, 152070) | (698, 809, 16468)\n",
      "FOLD2 | (6039, 7426, 151823) | (665, 865, 16715)\n",
      "FOLD3 | (5944, 7324, 151616) | (760, 967, 16922)\n",
      "FOLD4 | (6010, 7493, 150889) | (694, 798, 17649)\n",
      "FOLD5 | (6022, 7378, 151646) | (682, 913, 16892)\n",
      "FOLD6 | (6062, 7491, 151786) | (642, 800, 16752)\n",
      "FOLD7 | (6078, 7568, 151505) | (626, 723, 17033)\n",
      "FOLD8 | (6094, 7536, 151321) | (610, 755, 17217)\n",
      "FOLD9 | (6042, 7485, 152172) | (662, 806, 16366)\n",
      "FOLD10 | (6039, 7436, 152014) | (665, 855, 16524)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    t = tag_dists[i][\"train\"] \n",
    "    v = tag_dists[i][\"val\"]\n",
    "    print(f\"FOLD{i} | {t[0], t[1], t[2]} | {v[0], v[1], v[2]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-plane",
   "metadata": {},
   "source": [
    "* IDK, seems pretty good, a bit TOO good\n",
    "* Would probably need a little bit additional verification to check if folds are not too similar/dupplicate, but for now let's do a simple check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disturbed-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5223"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_5 = set(\" \".join(i) for i in joblib.load(folds_dir/\"fold2\"/\"train.bin\")[0])\n",
    "train_9 = set(\" \".join(i) for i in joblib.load(folds_dir/\"fold9\"/\"train.bin\")[0])\n",
    "len(train_5 & train_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-utilization",
   "metadata": {},
   "source": [
    "* Seems about right, since our train set is like 6k samples and valid is 800 it  woul make sense that 5.2k match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
